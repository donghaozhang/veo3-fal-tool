# Cursor AI Assistant Rules for Veo3 Video Generation Project

## Project Overview
This is a comprehensive AI content creation project with multiple implementations:
- Google Veo video generation (veo3_video_generation/)
- FAL AI video generation (fal_image_to_video/)  
- FAL AI avatar generation (fal_avatar_generation/)
- FAL AI text-to-image (fal_text_to_image/)
- FAL AI image-to-image (fal_image_to_image/)
- **NEW: Modular text-to-speech package (text_to_speech/)**
- **ENHANCED: Video tools with CLI parameter support (video_tools/)**

## Text-to-Speech Package Architecture (RECENTLY REFACTORED)

### Package Structure
The text_to_speech package has been refactored from monolithic files to a professional modular structure:

```
text_to_speech/
├── models/          # Data models and enums
│   ├── common.py    # Shared models (VoiceSettings, AudioFormat, etc.)
│   └── pipeline.py  # Pipeline-specific models
├── tts/             # Core TTS functionality
│   ├── controller.py      # Main TTS controller
│   ├── voice_manager.py   # Voice selection and management
│   └── audio_processor.py # Audio format handling
├── pipeline/        # OpenRouter AI integration
│   └── core.py      # Complete pipeline orchestration
├── utils/           # Utility functions
│   ├── file_manager.py    # File operations
│   ├── api_helpers.py     # API utilities
│   └── validators.py      # Input validation
├── config/          # Configuration management
│   ├── voices.py    # Voice presets and configurations
│   ├── models.py    # Model settings and recommendations
│   └── defaults.py  # Default values and settings
├── examples/        # Usage examples
│   └── basic_usage.py     # Basic TTS examples
└── cli/             # Command line tools
    ├── interactive.py     # Interactive pipeline
    └── quick_start.py     # Quick demo runner
```

### Import Patterns
**Always use the new modular imports:**
```python
# ✅ Correct - Main package interface
from text_to_speech import ElevenLabsTTSController, ElevenLabsModel, VoiceSettings

# ✅ Correct - Direct module imports
from text_to_speech.tts.controller import ElevenLabsTTSController
from text_to_speech.models.common import ElevenLabsModel, VoiceSettings
from text_to_speech.pipeline.core import OpenRouterTTSPipeline

# ❌ Avoid - Old monolithic imports (removed)
from elevenlabs_tts_controller import ElevenLabsTTSController  # FILE REMOVED
from openrouter_tts_pipeline import OpenRouterTTSPipeline      # FILE REMOVED
```

### Migration Notes
- Old monolithic files have been removed: elevenlabs_tts_controller.py, openrouter_tts_pipeline.py, elevenlabs_dialogue_controller.py
- All functionality preserved in new modular structure
- Migration guide available: text_to_speech/MIGRATION_GUIDE.md
- Backward compatibility maintained through main package interface

## Video Tools Enhanced CLI Architecture (RECENTLY IMPLEMENTED)

### Enhanced Commands with Parameter Support
The video_tools package now supports enhanced CLI parameter mode for specific commands:

```bash
# Enhanced generate-subtitles with -i, -o, -f parameters
python3 video_audio_utils.py generate-subtitles -i video.mp4 -o subtitle.srt
python3 video_audio_utils.py generate-subtitles -i input/ -o output/ -f vtt

# Enhanced describe-videos with parameters
python3 video_audio_utils.py describe-videos -i video.mp4 -o output.json -f describe-video

# Enhanced transcribe-videos with parameters  
python3 video_audio_utils.py transcribe-videos -i video.mp4 -o output.json -f json
```

### Parameter Support Pattern
Commands support enhanced mode when `-i`, `-o`, or `-f` parameters are provided:
- `-i`: Input file or directory path
- `-o`: Output file or directory path  
- `-f`: Format specification (varies by command)

### Implementation Pattern
Enhanced commands follow this architecture:
1. `cmd_[command]_enhanced()` wrapper function in video_audio_utils.py
2. `cmd_[command]_with_params()` implementation in respective modules
3. Automatic detection and routing based on parameter presence
4. Backward compatibility with traditional mode (no parameters)

## Development Guidelines

### Text-to-Speech Package
1. **Modular Design**: Keep modules focused (150-300 lines each)
2. **Clean Imports**: Use relative imports within package, absolute from outside
3. **Type Hints**: Always include proper type hints (remember `from typing import List`)
4. **Validation**: Use utils.validators for input validation
5. **Configuration**: Use config/ modules for settings and presets
6. **Testing**: Support dummy API keys for structure testing

### General Project Guidelines
1. **Cost Consciousness**: Always warn about API costs for FAL AI operations
2. **Environment Variables**: Use .env files for API keys, never commit them
3. **Error Handling**: Comprehensive error handling with user-friendly messages
4. **Documentation**: Update README files when adding features
5. **Testing**: Provide both FREE and paid testing options where applicable

### File Organization
- Each implementation has its own folder with clear separation
- Shared utilities in dedicated modules
- Comprehensive README files for each implementation
- Cost-conscious testing frameworks for paid APIs

### Code Style
- Use descriptive variable names
- Include comprehensive docstrings
- Follow Python PEP 8 guidelines
- Prefer composition over inheritance
- Keep functions focused and single-purpose

### API Integration Patterns
- Always validate API keys before making requests
- Implement retry logic with exponential backoff
- Provide detailed error messages for API failures
- Support both synchronous and asynchronous operations where appropriate
- Include rate limiting considerations

### Testing Strategy
- Provide FREE tests that validate structure without API calls
- Include cost warnings for all paid operations
- Support dummy/test API keys for development
- Comprehensive test suites with clear cost implications
- Interactive demos with user confirmation for paid operations

### Security Considerations
- Never commit API keys or sensitive information
- Use environment variables for configuration
- Validate all user inputs
- Implement proper error handling without exposing internals
- Use secure defaults for all configurations

## Specific Implementation Notes

### Google Veo (veo3_video_generation/)
- Requires Google Cloud authentication and complex setup
- Function-based architecture
- GCS bucket integration for file handling
- Comprehensive error handling for cloud operations

### FAL AI Implementations
- Class-based architecture across all FAL modules
- Unified error handling and cost protection
- Simple API key authentication
- Production-ready with cost-conscious design

### Text-to-Speech Package
- Professional modular architecture (recently refactored)
- Comprehensive pipeline: AI content generation → speech synthesis
- Support for 3000+ voices and multiple models
- Complete configuration management system
- CLI tools and interactive interfaces

### Video Tools Package
- Enhanced CLI architecture with parameter support (recently implemented)
- Supports both traditional mode and enhanced mode with parameters
- Subtitle generation: SRT/VTT format support with -i/-o/-f parameters
- AI analysis: describe-videos and transcribe-videos with parameter support
- Comprehensive test suite with automated CLI testing

## When Working on This Project

1. **Identify the Implementation**: Understand which component you're working with
2. **Check Documentation**: Each folder has its own README with specific guidelines
3. **Understand Cost Implications**: Be aware of which operations cost money
4. **Follow Architecture Patterns**: Use the established patterns for each implementation
5. **Test Appropriately**: Use FREE tests first, then paid tests with user confirmation
6. **Update Documentation**: Keep README files current with any changes
7. **For Text-to-Speech**: Use the new modular structure, not old monolithic files

## Common Commands

### Text-to-Speech Development
```bash
cd text_to_speech
pip install -r requirements.txt

# Test package structure (FREE)
python -c "from text_to_speech import ElevenLabsTTSController; print('✅ Package working!')"

# Run examples
python examples/basic_usage.py
python cli/interactive.py
python cli/quick_start.py
```

### Video Tools Development
```bash
cd video_tools

# Test enhanced CLI functionality
bash tests/test_subtitles_cli.sh

# Enhanced commands with parameters
python3 video_audio_utils.py generate-subtitles -i input/video.mp4 -o output/subtitle.srt -f srt
python3 video_audio_utils.py describe-videos -i input/video.mp4 -o output/description.json
python3 video_audio_utils.py transcribe-videos -i input/video.mp4 -o output/transcript.txt

# Traditional commands (no parameters)
python3 video_audio_utils.py generate-subtitles
python3 video_audio_utils.py describe-videos
```

### Other Implementations
```bash
# Google Veo
cd veo3_video_generation && python test_veo.py

# FAL AI (with cost warnings)
cd fal_image_to_video && python test_api_only.py  # FREE
cd fal_avatar_generation && python test_setup.py  # FREE
```

Remember: 
- The text_to_speech package has a completely refactored, professional modular architecture. Always use the new import patterns and module structure.
- The video_tools package now supports enhanced CLI mode with -i/-o/-f parameters for generate-subtitles, describe-videos, and transcribe-videos commands. Always check for parameter support when working with these commands.